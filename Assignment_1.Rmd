---
title: "Student Survey Analysis"
date: "18/09/2020"
output: 
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Introduction

A survey was conducted to collect the responses from students who are enrolled in DATA2X02. 

Students enrolled in DATA2X02 in Semester 2 were surveyed through voluntary response sample method. The aim of this analysis is to determine the following three hypotheses based on the response gathered: 

  * The number of COVID tests follow a Poisson distribution
  * Sufficient exercise time increases the risk of having asthma
  * Flossing Frequency and last visit to a dentist are independent of each other

```{r import_data, message=FALSE, warning=FALSE}
library(tidyverse)
library(janitor)
raw = readr::read_csv("survey.csv")

data = raw %>% janitor::clean_names()

num_row = nrow(data)
```

The survey conducted was a voluntary activity across the spam of four to five days. In summary, the population size is 572 students enrolled in DATA2X02 in semester 2, 2020. `r nrow(data)` students filled in the survey.

## Initial Data Cleaning
The data cleaning process is to:

  * Convert datatypes
  * Have a cleaned and shortened name in the table for each of the questions in the survey
  * Exclude any response with no user input but only the timestamp
  

### Cleaned column name
A quick summary of the questions and the associated variable name is shown below:
```{r data_clean}
colnames(data)[1] = "Timestamp"
colnames(data)[2] = "Num_test_COVID"
colnames(data)[4] = "Postcode"
colnames(data)[5] = "Last_visit_dentist"
colnames(data)[6] = "Hour_on_uni"
colnames(data)[7] = "Favourite_social_media"
colnames(data)[8] = "Dog_or_cat"
colnames(data)[9] = "Live_with_parents"
colnames(data)[10] = "Hour_exercising"
colnames(data)[11] = "Eye_colour"
colnames(data)[12] = "Asthma"
colnames(data)[13] = "Hour_paid_work"
colnames(data)[14] = "Favourite_season"
colnames(data)[15] = "Shoe_size"
colnames(data)[16] = "Height"
colnames(data)[17] = "Frequency_floss"
colnames(data)[18] = "Glasses"
colnames(data)[19] = "Dominant_hand"
colnames(data)[20] = "Steak"
colnames(data)[21] = "Stress_level"


tibble(Questionn = 1:21, `Variable name` = colnames(data), `Associated Questions` = colnames(raw)) %>%
  gt::gt() %>%
  gt::tab_source_note("Table 1: Variable name and associated survey question")
```

### Convert data types
The timestamps are converted from characters to data-time objects. The postcodes are converted from double class to characters as there is no qualitative characteristics (e.g. interval or ratio) to the postcode numbers. 
```{r convert_types}
data = data %>%
    mutate(Postcode = as.character(Postcode),
           Timestamp = lubridate::dmy_hms(Timestamp))
```


### Exclude survey response with no user input
The graph shows the presence of the missing values in the survey and where they are located. It indicates that there are a few observations that have missing values in every single column. These observations are removed, and now the dataset has 172 rows.
```{r drop_all_na}
visdat::vis_miss(data)
data_drop_na = data %>%
    filter(!is.na(data[2:21]))
```

The summary of the data is shown below. As shown in the information, shoe size ranges from 5 to 265 and height ranges from 1.47 to 195. The wide range is due to inconsistent unit of measurement. These two categories cannot be cleaned as the unit for the data is unclear.

```{r data_overview}
data_drop_na %>% skimr::skim()
```

### Is this a random sample of DATA2002 students?
This is not a random sample of the population of DATA2X02 students, as it is a voluntary exercise. For random sampling, each sample have an equal probability of being chosen, and they do not have the choice of choosing to participate. However, this survey allows the population to choose whether they want to participate in the survey.



### What are the potential biases? Which variables are most likely to be subjected to this bias?

Due to the nature of voluntary response sample and the short period of time that the survey was conducted, the potential bias may be that students who check their university emails often and are interested in participating in the survey are more likely to fill out their response.

The variables that are most subjected to this bias are:

  * Hour_on_uni. Active on university email and wanting to participate in class activity may suggest the students are proactive in their academic studies, thus spend more hours on university work

  * Glasses. These proactive students may need to engage with computer screen for a long time to complete their university tasks. This can impact their vision, and may influence their need for glasses or contacts.


### Are there any questions that needed improvement to generate useful data?

Many open questions that require students to type in a value can be improved by indicating what are the some acceptable values.

Questions that ask for a numeric answer, such as height and shoe size, can be improved by specify a standard unit. For example, the height is in centimeters and the shoe size is UK shoe size measurement.

Questions that ask for a text answer, such as the favourite social media platform, can benefit from indicating that it only looks for one social media platform in the response rather than multiple platforms. Also, it would be beneficial to provide some examples on how the names should be written in the response to standarise the format, such as captalisation and no abbreviation in the answer. This helps with data cleaning.



## Hypothesis 1: Does the number of COVID tests follow a Poisson distibution?
The number of COVID tests that the students have done til the closing date of the survey is shown in the bar graph below. Majority of the students have never done a COVID test, and the number of tests ranges from 0 to 10. This part of the analysis is to determine whether the number of COVID tests follow a Poisson distribution.

```{r covid_test_graph, warning=FALSE, message=FALSE}
library(ggplot2)

num_covid = data_drop_na %>%
  drop_na()

ggplot(num_covid, aes(x = Num_test_COVID)) + 
  geom_bar() +
  labs(caption = "Graph 1: Distribution of the number of COVID tests", x = "Number of COVID tests", y = "Count")

```

$H_0$: The number of COVID tests follow a Poisson distribution.

$H_1$: The number of COVID tests does not follow a Poisson distribution.

The Poisson distribution assumes that the expected frequencies $e_i = np_i \geq 5$, and the observations are independent. In this survey, the responses are independent as the students filled the questionnaire individually.

The NA values are dropped before testing the null hypothesis.

The parameter lambda is the average number of COVID-19 tests in a given interval (before the survey was closed). The calculated lambda is then used to compute the expected values for the dataset. As shown in Table 2, there are expected values that are smaller than 5. To make the assumption that all expected values are greater or equal to 5, row 3 to 8 are combined.

```{r covid_test_poisson}

num_covid_clean = data_drop_na %>%
  select(Num_test_COVID) %>%
  drop_na() %>%
  group_by(Num_test_COVID) %>%
  count()

x = num_covid_clean$Num_test_COVID
y = num_covid_clean$n
n = sum(y)
lam = sum(x*y)/n
p = dpois(x, lambda = lam)

p[8] = 1-sum(p[1:7])

expected_value = n*p


num_covid_clean$expected_values = expected_value
num_covid_clean$expected_greater_5 = expected_value >= 5

knitr::kable(num_covid_clean, caption = "Table 2: Poisson Distribution Calculation") 

y_combined = c(y[1:2], sum(y[3:8]))

expected_combined = c(expected_value[1:2], sum(expected_value[3:8]))
  
probability_combined = c(p[1:2], sum(p[3:8]))

num_class = length(y_combined)

test_stat = sum((y_combined - expected_combined)^2/(expected_combined))

pval = 1-pchisq(test_stat, df = num_class-1-1)
```
### Result
The p value is $9.336 * 10^{-6}$. It is smaller than the threshold of 0.05, thus there is insufficient evidence to show that this data follows a Poisson distribution.


## Hypothesis 2: Exercise increases the risk of getting asthma

The data for whether the students have asthma and the number of hours on exercising are extracted from the survey responses. The data is firstly cleaned to remove any responses with missing values in these two questions.

As shown in Graph 2, most of the students exercise between 0 to 20 hour a week, and there is one outlier who exercises for 70 hours a week. Among these responses, the students who have asthma mainly exercise for less than 10 hours. 


```{r exercise_asthma_cleaning}
exercise_asthma = data_drop_na %>%
  select(Hour_exercising, Asthma) %>%
  filter(!is.na(Hour_exercising) & !is.na(Asthma))

ggplot(exercise_asthma, aes(x = Hour_exercising, fill = Asthma)) + 
  geom_histogram(binwidth = 1) + 
  labs(caption = "Graph 2: Distribution of hours of exericising a week and asthma", x = "Hours of exericising a week", y = "Count")


```

This analysis is to examine the relationship between insufficient exercise and the risk of getting asthma. For the purpose of this analysis, insufficient exercise is defined as exercising for less than 30 minutes per day, thus less than `r 0.5*7` hours a week. Graph 3 categorises students into whether they have insufficient exercise per week and shows the distribution of whether they have asthma accordingly.

The number of students who have asthma are similar in the two categories with the number for the sufficient exercise group is slightly higher, however, there are more students with sufficient exercise hours per week. The hypothesis to be tested is that sufficient exercise time increases the risk of having asthma. 

```{r exercise_asthma_data}

exercise_asthma$exercise_insufficient = exercise_asthma$Hour_exercising < 3.5

ggplot(exercise_asthma, aes(x = exercise_insufficient, fill = Asthma)) + 
  labs(x = "Insufficient exercise", y = "Count", caption = "Graph 3: Distribution of insufficient exercise") + 
  geom_bar()

```

The analysis is a retrospective study where the number of people who have asthma is controlled, then examine the number of students on whether they have insufficient exercise.
```{r hypothesis_2_analysis}
asthma_insufficient = exercise_asthma %>%
  filter(exercise_insufficient == TRUE & Asthma == "Yes") %>%
  count()

no_asthma_insufficient = exercise_asthma %>%
  filter(exercise_insufficient == TRUE & Asthma == "No") %>%
  count()

asthma_sufficient = exercise_asthma %>%
  filter(exercise_insufficient == FALSE & Asthma == "Yes") %>%
  count()

no_asthma_sufficient = exercise_asthma %>%
  filter(exercise_insufficient == FALSE & Asthma == "No") %>%
  count()

c_table = matrix(c(asthma_insufficient$n, 
                 asthma_sufficient$n, 
                 no_asthma_insufficient$n, 
                 no_asthma_sufficient$n), ncol=2)

colnames(c_table) = c("Asthma: yes", "Asthma: no")
rownames(c_table) = c("Insufficient exercise: yes", "Insufficient exercise: no")
a = c_table[1, 1]
b = c_table[1, 2]
c = c_table[2, 1]
d = c_table[2, 2]
c_table = c_table %>%
  cbind(Total = rowSums(c_table))
c_table = c_table %>%
  rbind(Total = colSums(c_table))

knitr::kable(c_table, caption = "Table 3: Contingency table for asthma and insufficient exercise") 

```
### Result

The odds ratio calculated is 1.05668, meaning the odds of a student developing asthma given insufficient exercise is 1.05668 times larger than a student developing asthma given sufficient exercise. 

The log odds ratio is (-0.858, 0.9683), and the 95% odds confidence interval is (0.424, 2.6334). Since 0 lies inside the odds confidence interval and 1 lies inside the odds confidence interval, it is concluded that there is no relationship discovered and no evidennce to suggest that insufficient exercise is a risk factor for developing asthma.

```{r hypothesis_2_calculation}
odds_ratio = (a*d)/(b*c)

se_log = sqrt(1/a + 1/b + 1/c + 1/d)

log_confi_interval = c(log(odds_ratio)-qnorm(0.975)*se_log,
                   log(odds_ratio) + qnorm(0.975) * se_log)


confi_interval = exp(log_confi_interval)

```



## Hypothesis 3: Flossing Frequency and last visit to a dentist are independent of each other

The data for the flossing frequency and last time visiting a dentist are extracted from the responses. Any response with missing value in either of these two questions are excluded from this analysis. Table 4 summarises all the valid responses.

```{r}
dentist_floss = data_drop_na %>%
  select(Last_visit_dentist, Frequency_floss) %>%
  filter(!is.na(Last_visit_dentist) & !is.na(Frequency_floss))

floss_levels = c("Less than once a week", "Weekly", "Most days", "Every day")
last_visit_levels = c("Less than 6 months", "Between 6 and 12 months", "Between 12 months and 2 years", "More than 2 years")

dentist_floss = dentist_floss %>% 
  mutate(
    Last_visit_dentist = factor(Last_visit_dentist, levels = last_visit_levels), Frequency_floss = factor(Frequency_floss, levels = floss_levels)
  )


floss_dentist = table(dentist_floss$Last_visit_dentist, dentist_floss$Frequency_floss)

colnames(floss_dentist) = c("Floss: Every Day", "Floss: Less than once a week", "Floss: Most Days", "Floss: Weekly")
rownames(floss_dentist) = c("Last visit: Between 12 months and 2 years", "Last visit: 6 to 12 months", "Last visit: Less than 6 months", "Last visit: More than 2 years")
 

rt = rowSums(floss_dentist)
ct = colSums(floss_dentist)

c_floss_dentist = floss_dentist %>%
  cbind(Total = rowSums(floss_dentist))
c_floss_dentist = c_floss_dentist %>%
  rbind(Total = colSums(c_floss_dentist))

knitr::kable(c_floss_dentist, caption = "Table 4: Last Dentist Visit vs Floss Frequency")
```
The data in Table 4 is represented in Graph 4. Visually, there is no strong evidence to suggest a relationship between the floss frequency and last visit to a dentist. This analysis examines the hypothesis of floss frequency and last visit to a dentist are independent of each other.

```{r floss_visit_graph, fig.width=10}
ggplot(dentist_floss, aes(x = Last_visit_dentist, fill = Frequency_floss)) + 
  labs(x = "Last visit to the dentist", y = "Count", caption = "Graph 4: Distribution of last visit time to the dentist", fill = "Floss Frequency") +
  geom_bar()
```



### Results
The assumption for independence test is that the expected value is equal or greater than 5. However, as shown in Table 5, not all the expected values are equal or greater than 5.
```{r check_expected_value, warning=FALSE, message=FALSE}

e_i_check = chisq.test(floss_dentist)$expected >= 5
knitr::kable(e_i_check, caption = "Table 5: Expected value assumption check")
```

Thurs, Yates' Corrected chi-squared test is performed instead of a traditional chi-squared test. The calculated p-value is 0.4595. Monte-Carlo p-value is calculated from the distribution of simulated test statistic, which is represented in Graph 5. The value is 0.47135. As both of these values are larger than 0.05. It is concluded that at 5% significance level, last visit time to a dentist is independent of floss frequency.

```{r calculation, message = FALSE, warning=FALSE}
yates_corrected = chisq.test(floss_dentist, correct = TRUE)

set.seed(20)
B = 20000
random_stats = numeric(length = B)

rnd_table = r2dtable(B, r=rt, c=ct)
for (i in 1:B) {
  random_stats[i] = suppressWarnings(chisq.test(rnd_table[[i]])$statistic)
}


observed_stats = chisq.test(floss_dentist)$statistic

hist(random_stats, breaks = 100, 
     xlab = "Similated Test Statistic", 
     main = "Distribution of Simulated Test Statistic")


Monte_Carlo_var = mean(random_stats > observed_stats)
```

## Conclusion

Three conclusions are drawn from this analysis:

  - The number of COVID tests done by students does not follow a Poisson distribution
  - Insufficient exercise is not a risk factor for developing asthma
  - Last visit time to a dentist is independent of floss frequency
  
Some of the limitations are:

  - Not all student response have a valid answer to all questions
  - In the independence test for the frequency of flossing and last visit to a dentist, the assumption for independence test does not hold. Therefore, the p-value calculated may be incorrect
  
Future research direction may be to explore relationship between numerical variables.

## References

- Firke S (2020). janitor: Simple Tools for Examining and Cleaning Dirty Data. R package version 2.0.1. https://CRAN.R-project.org/package=janitor
- Iannone R, Joe Cheng and Barret Schloerke (2020). gt: Easily Create Presentation-Ready Display Tables. R package version 0.2.2. https://CRAN.R-project.org/package=gt
- R Core Team (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. https://www.R-project.org/
- Kirill Müller and Hadley Wickham (2020). tibble: Simple Data Frames.
R package version 3.0.3. https://CRAN.R-project.org/package=tibble
- Tierney N (2017). “visdat: Visualising Whole Data Frames.” JOSS, 2(16), 355. doi: 10.21105/joss.00355
- Waring E, Michael Quinn, Amelia McNamara, Eduardo Arino de la Rubia, Hao Zhu and Shannon Ellis (2020). skimr: Compact and Flexible Summaries of Data. R package version 2.1.2. https://CRAN.R-project.org/package=skimr
- Wickham H et al., (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686, doi: 10.21105/joss.01686
- H. Wickham. ggplot2: Elegant Graphics for Data Analysis.
  Springer-Verlag New York, 2016
- Yihui Xie (2015) Dynamic Documents with R and knitr. 2nd edition.
  Chapman and Hall/CRC. ISBN 978-1498716963
